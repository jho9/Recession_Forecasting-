{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sep_by_class(X_train, y_train):\n",
    "    labels = []\n",
    "    mean = []\n",
    "    std = []\n",
    "    X_train = pd.DataFrame(X_train)\n",
    "    y_train = pd.Series(y_train)\n",
    "    arr_of_labels = (y_train).unique()\n",
    "    num_of_class = len(pd.Series(y_train).unique())\n",
    "    #print(\"There are:\", num_of_class, \"classes of the y label\")\n",
    "    #print(\"The labels are:\", arr_of_labels)\n",
    "    for i in arr_of_labels:\n",
    "        #print(\"Row seperated by label of:\", i)\n",
    "        labels.append(i)\n",
    "        #print(X_train[(y_train == i)])\n",
    "        #print(\"Mean of the value:\")\n",
    "        mean.append((X_train[(y_train == i)]).mean())\n",
    "        #print(\"Standard deviation: \")\n",
    "        std.append((X_train[(y_train == i)]).std())\n",
    "    return labels, mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateProbability(x, mean, stdev):\n",
    "    stdev = np.array(stdev)\n",
    "    exponent = (np.exp((np.array(-(x - mean)**2))/np.array((2*(stdev**2)))))\n",
    "    return (1 / (math.sqrt(2*math.pi) * stdev)) * exponent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_class_probability(labels, mean, std, x):\n",
    "    #print(\"There are:\", len(x), \"features in X_test\")\n",
    "    class_probs = []\n",
    "    for i in range(len(labels)):\n",
    "        #print(labels[i])\n",
    "        #print(x)\n",
    "        #print(mean[i])\n",
    "        #print(std[i])\n",
    "        probs = np.prod(calculateProbability(x, (mean[i]), (std[i])))\n",
    "        #print(probs)\n",
    "        #print(probs)\n",
    "        class_probs.append(probs)\n",
    "    return class_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cond_prob(feat_1, feat_2):\n",
    "    feat_1 = pd.Series(feat_1)\n",
    "    feat_2 = pd.Series(feat_2)\n",
    "    summation = []\n",
    "    #print(feat_1)\n",
    "    #print(feat_2)\n",
    "    #print(feat_1.value_counts().divide(len(feat_1)))\n",
    "    #print(feat_1)\n",
    "    for i in (feat_1.unique()):\n",
    "        #print(\"Given the value of:\", i, \"from feature 1\")\n",
    "        #print((feat_1[feat_1 == i]))\n",
    "        #print((feat_1[feat_1 == i]).index)\n",
    "        #print(feat_2[(feat_1[feat_1 == i]).index])\n",
    "        #print(feat_1 == i)\n",
    "        #print(i)\n",
    "        cond_proba = (feat_2[(feat_1[feat_1 == i]).index]).value_counts().divide(len(feat_1))\n",
    "        #print(cond_proba)\n",
    "        proba = (feat_1.value_counts().divide(len(feat_1)))\n",
    "        #print(\"These are the values for the probability of feature 1:\")\n",
    "        #print(proba)\n",
    "        summation.append(proba * cond_proba)\n",
    "        #print(summation)\n",
    "    #print(pd.DataFrame(summation))\n",
    "    return ((pd.DataFrame(summation)).sum(axis = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NB_predict(X_train, y_train, X_test, y_lag= [], weight = 'yes'):\n",
    "    labels, mean, std = sep_by_class(X_train, y_train)\n",
    "    y_train = pd.Series(y_train)\n",
    "    class_probs = []\n",
    "    if weight == 'yes':\n",
    "        prob_of = ((y_train.value_counts()).divide(len(y_train)))\n",
    "    elif weight == 'markov':\n",
    "        prob_of = cond_prob(y_lag, y_train)\n",
    "    elif weight == 'no':\n",
    "        prob_of = 1\n",
    "    #print(prob_of)\n",
    "    \"\"\"\n",
    "    for i in (y_lag_test).values:\n",
    "        prob_of = prob_of.loc[i]\n",
    "    \"\"\"\n",
    "    X_test = pd.DataFrame(X_test)\n",
    "    for i in range(len(X_test)):\n",
    "            #print(i)\n",
    "            #print(X_test.iloc[i,:])\n",
    "        class_probs.append(prob_of*(pd.Series(calculate_class_probability(labels,mean, std, X_test.iloc[i,:]), labels)))\n",
    "    predicted_labels = []\n",
    "    #print(class_probs)\n",
    "    for i in range(len(class_probs)):\n",
    "        predicted_labels.append((class_probs[i]).idxmax())\n",
    "    return predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train up up to 168 then start forcasting in a window after 168\n",
    "def window_tester(X, y, init_train_indx):\n",
    "    lst_of_predicted = []\n",
    "    lst_of_actual = []\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    #print(X[:,:])\n",
    "    for i in range(init_train_indx + 1,len(y)):\n",
    "        X_train = X[:i-1,:]\n",
    "        y_train = y[:i-1]\n",
    "        X_test = X[[i][:]]\n",
    "        y_test = y[i]\n",
    "        #clf.fit(X = X_train, y = y_train)\n",
    "        y_pred = NB_predict(X_train, y_train, X_test)\n",
    "        #print(y_pred)\n",
    "        lst_of_predicted.append(y_pred)\n",
    "        lst_of_actual.append(y_test)\n",
    "        #print(\"This is y_pred:   \", y_pred)\n",
    "        #print(\"This is y_actual: \", y_test)\n",
    "    return lst_of_predicted, lst_of_actual\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path = \"C://Users//James//Downloads//macro_data.csv\"\n",
    "path = \"C://Users//James//Downloads//macro_data_transformed.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(path, index_col='Unnamed: 0')\n",
    "df = df.drop(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    sasdate  NAPMPI  PAYEMS  T10YFFM   S.P.500  rec_dates\n",
      "2  1/1/1959    70.7   207.0     1.54 -0.015400        0.0\n",
      "3  2/1/1959    70.3   329.0     1.53  0.025062        0.0\n",
      "4  3/1/1959    71.2   304.0     1.19  0.016599        0.0\n",
      "5  4/1/1959    72.1   229.0     1.16  0.014949        0.0\n",
      "6  5/1/1959    73.9   130.0     1.41 -0.008664        0.0\n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1\n",
      "Overall accuracy:\n",
      "0.8185328185328186\n",
      "Precision Accuracy\n",
      "0.1111111111111111\n",
      "Recall Accuracy\n",
      "0.21052631578947367\n",
      "True Negative Rate\n",
      "0.8666666666666667\n",
      "Negative Predictive Value\n",
      "0.9327354260089686\n",
      "-3\n",
      "Overall accuracy:\n",
      "0.8410852713178295\n",
      "Precision Accuracy\n",
      "0.2777777777777778\n",
      "Recall Accuracy\n",
      "0.4\n",
      "True Negative Rate\n",
      "0.8884120171673819\n",
      "Negative Predictive Value\n",
      "0.9324324324324325\n",
      "-6\n",
      "Overall accuracy:\n",
      "0.884990253411306\n",
      "Precision Accuracy\n",
      "0.4444444444444444\n",
      "Recall Accuracy\n",
      "0.6274509803921569\n",
      "True Negative Rate\n",
      "0.9134199134199135\n",
      "Negative Predictive Value\n",
      "0.9569160997732427\n",
      "-9\n",
      "Overall accuracy:\n",
      "0.9235294117647059\n",
      "Precision Accuracy\n",
      "0.6527777777777778\n",
      "Recall Accuracy\n",
      "0.7704918032786885\n",
      "True Negative Rate\n",
      "0.9443207126948775\n",
      "Negative Predictive Value\n",
      "0.9680365296803652\n",
      "-12\n",
      "Overall accuracy:\n",
      "0.9467455621301775\n",
      "Precision Accuracy\n",
      "0.782608695652174\n",
      "Recall Accuracy\n",
      "0.8181818181818182\n",
      "True Negative Rate\n",
      "0.9659863945578231\n",
      "Negative Predictive Value\n",
      "0.9726027397260274\n"
     ]
    }
   ],
   "source": [
    "features = ['NAPMPI', 'PAYEMS', 'T10YFFM','S.P.500']\n",
    "target = 'rec_dates'\n",
    "#month of is it a recession\n",
    "#y = df[target]\n",
    "\n",
    "#next month is it a recession\n",
    "horizon = [-1,-3,-6,-9,-12]\n",
    "from sklearn.metrics import confusion_matrix\n",
    "for val in horizon:\n",
    "    X = df[features]\n",
    "    print(val)\n",
    "    y = df['rec_dates'].shift(val)\n",
    "    X = X.iloc[:val,:]\n",
    "    y = y.iloc[:val]\n",
    "    y_pred, y_true = window_tester(X,y,168)\n",
    "    TP = confusion_matrix(pd.DataFrame(y_true),pd.DataFrame(y_pred))[1][0]\n",
    "    FP = confusion_matrix(pd.DataFrame(y_true),pd.DataFrame(y_pred))[1][1]\n",
    "    TN = confusion_matrix(pd.DataFrame(y_true),pd.DataFrame(y_pred))[0][0]\n",
    "    FN = confusion_matrix(pd.DataFrame(y_true),pd.DataFrame(y_pred))[0][1]\n",
    "    print(\"Overall accuracy:\")\n",
    "    print((TP +TN)/(TP + TN + FP + FN))\n",
    "    print(\"Precision Accuracy\")\n",
    "    print(TP/(TP + FP))\n",
    "    print(\"Recall Accuracy\")\n",
    "    print(TP/(TP + FN))\n",
    "    print(\"True Negative Rate\")\n",
    "    print(TN/(TN + FP))\n",
    "    print(\"Negative Predictive Value\")\n",
    "    print(TN/(TN + FN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
